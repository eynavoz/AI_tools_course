{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install before starting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.74.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\eynavoz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.3.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\eynavoz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "     ---------------------------------------- 0.0/65.2 kB ? eta -:--:--\n",
      "     ------------------------- -------------- 41.0/65.2 kB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 65.2/65.2 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\eynavoz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting typing-extensions<5,>=4.11 (from openai)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\eynavoz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\eynavoz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\eynavoz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\eynavoz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\eynavoz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.74.0-py3-none-any.whl (644 kB)\n",
      "   ---------------------------------------- 0.0/644.8 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 112.6/644.8 kB 6.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 286.7/644.8 kB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 450.6/644.8 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 644.8/644.8 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.9.0-cp312-cp312-win_amd64.whl (207 kB)\n",
      "   ---------------------------------------- 0.0/208.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 208.0/208.0 kB ? eta 0:00:00\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "   ---------------------------------------- 0.0/443.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 443.6/443.6 kB 14.0 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.33.1-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.9/2.0 MB 27.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 24.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 20.7 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.8/45.8 kB ? eta 0:00:00\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, jiter, distro, annotated-types, typing-inspection, pydantic-core, pydantic, openai\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.9.0 openai-1.74.0 pydantic-2.11.3 pydantic-core-2.33.1 tqdm-4.67.1 typing-extensions-4.13.2 typing-inspection-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.74.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: c:\\Users\\eynavoz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "#import gt\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## open AI connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_OPENAI_API_KEY = os.getenv('CLASS_AZURE_KEY')\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv('SUBSCRIPTION_OPENAI_ENDPOINT')\n",
    "\n",
    "MODEL_4o = 'gpt-4o-mini'\n",
    "OPENAI_API_VERSION_4o = '2024-08-01-preview'\n",
    "\n",
    "MODEL_35 = 'gpt-35-16k'\n",
    "OPENAI_API_VERSION_35 = '2023-12-01-preview'\n",
    "\n",
    "\n",
    "TEMP_1 = 0\n",
    "TEMP_2 = .5\n",
    "TEMP_3 = .9\n",
    "MAX_TOKENS = 7000\n",
    "LOG_PROBS = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Calories: The total number of calories in each dish is essential for customers to make informed choices about their calorie intake.\n",
      "\n",
      "2. Macronutrients: Include the amounts of carbohydrates, proteins, and fats in each dish. This information is crucial for individuals following specific dietary plans or those looking to balance their macronutrient intake.\n",
      "\n",
      "3. Fiber: The amount of dietary fiber in each dish is important for promoting digestive health and maintaining satiety.\n",
      "\n",
      "4. Sugar: Specify the amount of added sugars in each dish, as excessive sugar consumption can contribute to various health issues.\n",
      "\n",
      "5. Sodium: Provide the sodium content to help individuals monitor their sodium intake, especially for those with high blood pressure or other health conditions.\n",
      "\n",
      "6. Allergens: Clearly indicate if any common allergens, such as gluten, dairy, nuts, or shellfish, are present in the dish to ensure the safety of customers with food allergies.\n",
      "\n",
      "7. Serving Size: Clearly state the recommended serving size for each dish to help customers understand portion control and manage their calorie intake.\n",
      "\n",
      "8. Vitamins and Minerals: Highlight any significant vitamins and minerals present in the dish, such as vitamin C, iron, or calcium, to inform customers about the nutritional benefits.\n",
      "\n",
      "9. Ingredients: Provide a list of ingredients used in each dish to help customers with specific dietary restrictions or preferences, such as vegetarian, vegan, or gluten-free diets.\n",
      "\n",
      "10. Preparation Methods: Include information about how the dish is prepared, such as grilling, baking, or frying, to help customers make choices based on their preferred cooking methods or dietary needs.\n"
     ]
    }
   ],
   "source": [
    "#Example usage with model 35:\n",
    "client = AzureOpenAI(\n",
    "    api_key= AZURE_OPENAI_API_KEY,\n",
    "    api_version= OPENAI_API_VERSION_35,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    ")\n",
    "\n",
    "sys_prompt = {\"role\": \"system\", \"content\": \"You are a dietitian and a nutrition expert.\"}\n",
    "user_prompt = {\"role\": \"user\", \"content\": \"\"\"A restaurant wants to provide nutritional information \\\n",
    "for each dish (menu item) it offers. What information should it provide?\n",
    "Limit your response to no more than 10 requirements.\"\"\"}\n",
    "msg = [sys_prompt, user_prompt]\n",
    "responses = client.chat.completions.create(messages=msg, model=MODEL_35, temperature=TEMP_1, max_tokens=MAX_TOKENS, logprobs= LOG_PROBS, n=1)\n",
    "print(responses.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created function for convenience\n",
    "\n",
    "def generate_response(version, system_prompt, prompt, model, temp):\n",
    "    \"\"\"\n",
    "    Get a response from the specified OpenAI model using the given prompt.\n",
    "    \n",
    "    Args:\n",
    "        version (str): OPEN_API_VERSION\n",
    "        system_prompt (str): The system prompt to provide the model\n",
    "        prompt (str): The prompt to provide to the open AI model\n",
    "        model (str): The name of ID of the openAI engine to use\n",
    "        temp (str): the temperature parameter\n",
    "    \"\"\"\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        api_key= AZURE_OPENAI_API_KEY,\n",
    "        api_version= version,\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    )\n",
    "    sys_prompt = {\"role\": \"system\", \"content\": system_prompt}\n",
    "    user_prompt = {\"role\": \"user\", \"content\": prompt}\n",
    "    msg = [sys_prompt, user_prompt]\n",
    "    responses = client.chat.completions.create(messages=msg, model=model, temperature=temp, max_tokens=MAX_TOKENS, logprobs= LOG_PROBS, n=1)\n",
    "    return responses.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Calories: The total number of calories in each dish is essential for customers to make informed choices about their calorie intake.\\n\\n2. Macronutrients: Include the amounts of carbohydrates, proteins, and fats in each dish. This information is crucial for individuals following specific dietary plans or those looking to balance their macronutrient intake.\\n\\n3. Fiber: The amount of dietary fiber in each dish is important for customers who want to increase their fiber intake for digestive health and satiety.\\n\\n4. Sodium: Many people need to monitor their sodium intake due to health conditions like high blood pressure. Including the sodium content in each dish helps customers make lower-sodium choices.\\n\\n5. Sugar: The amount of added sugars in each dish is important for individuals who are watching their sugar intake, especially those with diabetes or those trying to reduce their overall sugar consumption.\\n\\n6. Allergens: Clearly indicate if any common allergens, such as gluten, dairy, nuts, or shellfish, are present in the dish. This information is crucial for customers with food allergies or intolerances.\\n\\n7. Portion Size: Provide the recommended serving size for each dish to help customers understand the appropriate portion and manage their calorie intake.\\n\\n8. Vitamins and Minerals: Highlight any significant vitamins and minerals present in the dish, such as vitamin C, iron, or calcium. This information can help customers meet their daily nutrient needs.\\n\\n9. Ingredients: List all the ingredients used in the dish to help customers with specific dietary restrictions or preferences, such as vegetarian, vegan, or gluten-free diets.\\n\\n10. Preparation Methods: Include information about how the dish is prepared, such as grilling, baking, or frying. This can help customers make choices based on their preferred cooking methods or dietary preferences.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example usage with model 35:\n",
    "\n",
    "sys_prompt1 = \"You are a dietitian and a nutrition expert.\"\n",
    "user_prompt1 = \"\"\"A restaurant wants to provide nutritional information \\\n",
    "for each dish (menu item) it offers. What information should it provide?\n",
    "Limit your response to no more than 10 requirements.\"\"\"\n",
    "generate_response(OPENAI_API_VERSION_35, sys_prompt1, user_prompt1, MODEL_35, TEMP_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file, tkts_1.txt\n",
    "\n",
    "# For each ticket in the file, your program needs to read the ticket and prompt the LLM \n",
    "# to determine if the ticket is a single issue or is really 2 different issues.\n",
    "\n",
    "sys_prompt_part1 = \"You are a helpful assistant that classifies support tickets.\"\n",
    "\n",
    "user_prompt_part1 = \"\"\"\n",
    "You are given a ticket of a software bug that a customer experiences. \n",
    "Your task is to determine if a ticket describes a single issue or is really 2 different issues.\n",
    "\n",
    "Use the following categories for issues classification:\n",
    "- Interface\n",
    "- Lacking Feature\n",
    "- Logic Defect\n",
    "- Data\n",
    "- Security and Access Control\n",
    "- Configuration\n",
    "- Stability\n",
    "- performance\n",
    "\n",
    "Eamples\n",
    "Here is the tickect to classify:\n",
    "{ticket}\n",
    "End of ticket\n",
    "\n",
    "Be concise and structured in your output. Return your result ONLY in this format:\n",
    "{{\n",
    "Issue Count: [1 or 2]\n",
    "Issue 1: category name\n",
    "Detail 1: short summary to support your decision\n",
    "Issue 2: categor name (Only include this if there are 2 issues.)\n",
    "Detail 2: short summary to support your decision\n",
    "}}\n",
    "Do not add any additional text besides this format.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "Issue Count: 1\n",
      "Issue 1: Stability\n",
      "Detail 1: The app crashes when uploading large files, indicating a stability issue.\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "ticket = \"The app crashes when uploading large files.\"\n",
    "print(generate_response(OPENAI_API_VERSION_35, sys_prompt_part1, user_prompt_part1.format(ticket=ticket), MODEL_35, TEMP_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ticket_file(file_path):\n",
    "    tickets = []\n",
    "\n",
    "    # Read the file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Parse each line\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            match = re.match(r\"(\\d+):\\s*(.+)\", line)\n",
    "            if match:\n",
    "                number = int(match.group(1))\n",
    "                ticket = match.group(2)\n",
    "                tickets.append({'number': number, 'ticket': ticket})\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(tickets)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./tkts_1.txt\"\n",
    "df = parse_ticket_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>ticket</th>\n",
       "      <th>llm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The buttons on the dashboard are misaligned af...</td>\n",
       "      <td>{\\nIssue Count: 1\\nIssue 1: Interface\\nDetail ...</td>\n",
       "      <td>no-split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>User roles are not saving correctly; some user...</td>\n",
       "      <td>{\\nIssue Count: 2\\nIssue 1: Data\\nDetail 1: Us...</td>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Clicking ‘Submit’ twice causes duplicate recor...</td>\n",
       "      <td>{\\nIssue Count: 1\\nIssue 1: Logic Defect\\nDeta...</td>\n",
       "      <td>no-split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Some reports show incorrect calculations, and ...</td>\n",
       "      <td>{\\nIssue Count: 2\\nIssue 1: Logic Defect\\nDeta...</td>\n",
       "      <td>split</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number                                             ticket  \\\n",
       "0       1  The buttons on the dashboard are misaligned af...   \n",
       "1       2  User roles are not saving correctly; some user...   \n",
       "2       3  Clicking ‘Submit’ twice causes duplicate recor...   \n",
       "3       4  Some reports show incorrect calculations, and ...   \n",
       "\n",
       "                                                 llm     class  \n",
       "0  {\\nIssue Count: 1\\nIssue 1: Interface\\nDetail ...  no-split  \n",
       "1  {\\nIssue Count: 2\\nIssue 1: Data\\nDetail 1: Us...     split  \n",
       "2  {\\nIssue Count: 1\\nIssue 1: Logic Defect\\nDeta...  no-split  \n",
       "3  {\\nIssue Count: 2\\nIssue 1: Logic Defect\\nDeta...     split  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['llm'] = df['ticket'].apply(lambda x: generate_response(OPENAI_API_VERSION_35, sys_prompt_part1, user_prompt_part1.format(ticket=x), MODEL_35, TEMP_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_llm_response(response_text):\n",
    "    if not isinstance(response_text, str):\n",
    "        return 'unknown'\n",
    "    \n",
    "    match = re.search(r\"Issue\\s*Count\\s*:\\s*(\\d+)\", response_text, re.IGNORECASE)\n",
    "    \n",
    "    if match:\n",
    "        count = int(match.group(1))\n",
    "        if count == 1:\n",
    "            return 'no-split'\n",
    "        elif count == 2:\n",
    "            return 'split'\n",
    "    \n",
    "    return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['llm'].apply(classify_llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results written to split.txt\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    {\"model\": MODEL_35, \"version\": OPENAI_API_VERSION_35, \"temperature\": 0},\n",
    "    {\"model\": MODEL_4o, \"version\": OPENAI_API_VERSION_4o,\"temperature\": 0},\n",
    "    {\"model\": MODEL_4o, \"version\": OPENAI_API_VERSION_4o,\"temperature\": 0.9}\n",
    "]\n",
    "\n",
    "# ==== Output Collector ====\n",
    "output_lines = []\n",
    "\n",
    "# ==== Processing ====\n",
    "for idx, row in df.iterrows():\n",
    "    ticket_number = row['number']\n",
    "    ticket_text = row['ticket']\n",
    "    output_lines.append(f\"{ticket_number}:\")\n",
    "\n",
    "    for test in tests:\n",
    "        model = test['model']\n",
    "        temp = test['temperature']\n",
    "        version = test['version']\n",
    "        try:\n",
    "            response = generate_response(\n",
    "                version,  # Or adapt if version changes\n",
    "                sys_prompt_part1,\n",
    "                user_prompt_part1.format(ticket=ticket_text),\n",
    "                model,\n",
    "                temp\n",
    "            )\n",
    "            llm_output = response.strip()\n",
    "        except Exception as e:\n",
    "            llm_output = f\"ERROR: {e}\"\n",
    "\n",
    "        classification = classify_llm_response(llm_output)\n",
    "        output_lines.append(f\"{model}, {temp}: {classification}\")\n",
    "        output_lines.append(f\"LLM response: {llm_output}\")\n",
    "\n",
    "        time.sleep(5)  # Wait to avoid hitting token rate limits\n",
    "    \n",
    "    output_lines.append(\"\")  # Empty line between tickets\n",
    "\n",
    "# ==== Save to File ====\n",
    "with open(\"split.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(output_lines))\n",
    "\n",
    "print(\"✅ Results written to split.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
